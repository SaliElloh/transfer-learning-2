{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import wget\n",
    "from zipfile import PyZipFile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import cv2\n",
    "import h5py\n",
    "import glob\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories for Data\n",
    "temp_directory = 'data/temp'\n",
    "orig_dir = 'data/images'\n",
    "train_directory = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "aug_images_directory = train_directory + '/augumented_images'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivFace_images = \"C:/Users/selloh/Desktop/Datasets/DrivFace/DrivImages\"\n",
    "# drivFace_images = './datasets/Drivface/DrivImages'\n",
    "# drivFace_annotations = './datasets/DrivFace/drivPoints.txt'\n",
    "drivFace_annotations = 'C:/Users/selloh/Desktop/Datasets/DrivFace/drivPoints.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00378/DrivFace.zip'\n",
    "# File name of the output of pre processing\n",
    "hdf5_path = 'DrivFace.h5'\n",
    "# Shape of input data\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "CHANNELS = 3\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = 'DrivFace.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "# landmark_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "def load_dataset():\n",
    "  if not os.path.exists(train_directory):\n",
    "    os.makedirs(temp_directory)\n",
    "    os.makedirs(train_directory)\n",
    "    print(\"Downloading dataset to \"+ temp_directory)\n",
    "    file = wget.download(url, out=temp_directory)\n",
    "    print(\"\\nUnzipping the files..\")\n",
    "    pzf = PyZipFile(file)\n",
    "    pzf.extractall(temp_directory)\n",
    "    pzf = PyZipFile(temp_directory+'/DrivFace/DrivImages.zip')\n",
    "    pzf.extractall(temp_directory)\n",
    "    print(\"Moving files to \"+train_directory)\n",
    "    for file in os.listdir(temp_directory+'/DrivImages'):\n",
    "      shutil.move(temp_directory+'/DrivImages/'+file,train_directory+'/'+file)\n",
    "    shutil.move(temp_directory+'/DrivFace/drivPoints.txt',train_directory+'/drivPoints.txt')\n",
    "    print(\"Deleting temporary directory \"+ temp_directory)\n",
    "    shutil.rmtree(temp_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(image_path):\n",
    "    base_name = os.path.basename(image_path).split('.')[0]\n",
    "    annotations = pd.read_csv(drivFace_annotations)\n",
    "    annotation = annotations[annotations['fileName'].str.contains(base_name)].iloc[0]\n",
    "\n",
    "    landmarks = {\n",
    "        \"xF\": annotation['xF'], \"yF\": annotation['yF'], \"wF\": annotation['wF'], \"hF\": annotation['hF'],\n",
    "        \"xRE\": annotation['xRE'], \"yRE\": annotation['yRE'],\n",
    "        \"xLE\": annotation['xLE'], \"yLE\": annotation['yLE'],\n",
    "        \"xN\": annotation['xN'], \"yN\": annotation['yN'],\n",
    "        \"xRM\": annotation['xRM'], \"yRM\": annotation['yRM'],\n",
    "        \"xLM\": annotation['xLM'], \"yLM\": annotation['yLM']\n",
    "    }\n",
    "\n",
    "    pose = annotation['label']\n",
    "\n",
    "    return landmarks, pose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augumented_images(directory):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    else:\n",
    "        return\n",
    "    print(\"Generating augumented images in the directory \" + directory)\n",
    "    for index, row in df_label.iterrows():\n",
    "            file = row['fileName'] + \".jpg\"\n",
    "            image = cv2.imread(train_directory + '/' + file)\n",
    "            y = int(row['yF'])\n",
    "            x = int(row['xF'])\n",
    "            w = int(row['wF'])\n",
    "            h = int(row['hF'])\n",
    "            #image = image[y:y+h, x:x+w]\n",
    "            image = cv2.resize(image, (HEIGHT, WIDTH), interpolation = cv2.INTER_AREA)\n",
    "            X = img_to_array(image)\n",
    "            X = X.reshape((1,) + X.shape)\n",
    "            i = 0\n",
    "            for batch in datagen.flow(X, batch_size=1,\n",
    "                              save_to_dir=directory, save_prefix=file, save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > 20:\n",
    "                    break  # otherwise the generator would loop indefinitely\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_images():\n",
    "    num_images = 0\n",
    "    dataset_X = []\n",
    "    dataset_y = []\n",
    "    if os.path.isfile(hdf5_path):\n",
    "        return\n",
    "    else:\n",
    "        print(\"writing images to \" + hdf5_path)\n",
    "        with h5py.File(hdf5_path, mode='w') as hf:\n",
    "            for index, row in df_label.iterrows():\n",
    "                file = row['fileName'] + \".jpg\"\n",
    "                image = cv2.imread(train_directory + '/' + file)\n",
    "                y = int(row['yF'])\n",
    "                x = int(row['xF'])\n",
    "                w = int(row['wF'])\n",
    "                h = int(row['hF'])\n",
    "                #image = image[y:y+h, x:x+w]\n",
    "                image = cv2.resize(image, (HEIGHT, WIDTH), interpolation = cv2.INTER_AREA)\n",
    "                dataset_X.append(image)\n",
    "                dataset_y.append(row['label'])\n",
    "                num_images = num_images + 1\n",
    "                for augumented_image in glob.glob(train_directory + '/augumented_images/' + file + \"*\"):\n",
    "                    image = cv2.imread(augumented_image)\n",
    "                    y = int(row['yF'])\n",
    "                    x = int(row['xF'])\n",
    "                    w = int(row['wF'])\n",
    "                    h = int(row['hF'])\n",
    "                    #image = image[y:y+h, x:x+w]\n",
    "                    image = cv2.resize(image, (HEIGHT, WIDTH), interpolation = cv2.INTER_AREA)\n",
    "                    dataset_X.append(image)\n",
    "                    dataset_y.append(row['label'])\n",
    "                    num_images = num_images + 1\n",
    "            dataset_X = hf.create_dataset(\n",
    "                    name='dataset_X',\n",
    "                    data=dataset_X,\n",
    "                    shape=(len(dataset_X), HEIGHT, WIDTH, CHANNELS),\n",
    "                    maxshape=(len(dataset_X), HEIGHT, WIDTH, CHANNELS),\n",
    "                    compression=\"gzip\",\n",
    "                    compression_opts=9)\n",
    "            dataset_y = hf.create_dataset(\n",
    "                    name='dataset_y',\n",
    "                    data=dataset_y,\n",
    "                    shape=(len(dataset_y), 1,),\n",
    "                    maxshape=(len(dataset_y), None,),\n",
    "                    compression=\"gzip\",\n",
    "                    compression_opts=9)\n",
    "            number_images = next(os.walk(train_directory))[2]\n",
    "            number_images_aug = next(os.walk(aug_images_directory))[2]\n",
    "            print(\"Number of images written to \"+ hdf5_path + \" is: \" + str(len(number_images)+len(number_images_aug)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>subject</th>\n",
       "      <th>imgNum</th>\n",
       "      <th>label</th>\n",
       "      <th>ang</th>\n",
       "      <th>xF</th>\n",
       "      <th>yF</th>\n",
       "      <th>wF</th>\n",
       "      <th>hF</th>\n",
       "      <th>xRE</th>\n",
       "      <th>yRE</th>\n",
       "      <th>xLE</th>\n",
       "      <th>yLE</th>\n",
       "      <th>xN</th>\n",
       "      <th>yN</th>\n",
       "      <th>xRM</th>\n",
       "      <th>yRM</th>\n",
       "      <th>xLM</th>\n",
       "      <th>yLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20130529_01_Driv_001_f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>209</td>\n",
       "      <td>100</td>\n",
       "      <td>112</td>\n",
       "      <td>323</td>\n",
       "      <td>232</td>\n",
       "      <td>367</td>\n",
       "      <td>231</td>\n",
       "      <td>353</td>\n",
       "      <td>254</td>\n",
       "      <td>332</td>\n",
       "      <td>278</td>\n",
       "      <td>361</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20130529_01_Driv_002_f</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>200</td>\n",
       "      <td>109</td>\n",
       "      <td>128</td>\n",
       "      <td>324</td>\n",
       "      <td>235</td>\n",
       "      <td>366</td>\n",
       "      <td>235</td>\n",
       "      <td>353</td>\n",
       "      <td>258</td>\n",
       "      <td>333</td>\n",
       "      <td>281</td>\n",
       "      <td>361</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130529_01_Driv_003_f</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>204</td>\n",
       "      <td>105</td>\n",
       "      <td>121</td>\n",
       "      <td>325</td>\n",
       "      <td>240</td>\n",
       "      <td>367</td>\n",
       "      <td>239</td>\n",
       "      <td>351</td>\n",
       "      <td>260</td>\n",
       "      <td>334</td>\n",
       "      <td>282</td>\n",
       "      <td>362</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20130529_01_Driv_004_f</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>202</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>325</td>\n",
       "      <td>230</td>\n",
       "      <td>369</td>\n",
       "      <td>230</td>\n",
       "      <td>353</td>\n",
       "      <td>253</td>\n",
       "      <td>335</td>\n",
       "      <td>274</td>\n",
       "      <td>362</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20130529_01_Driv_005_f</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>193</td>\n",
       "      <td>104</td>\n",
       "      <td>119</td>\n",
       "      <td>325</td>\n",
       "      <td>224</td>\n",
       "      <td>366</td>\n",
       "      <td>225</td>\n",
       "      <td>353</td>\n",
       "      <td>244</td>\n",
       "      <td>333</td>\n",
       "      <td>268</td>\n",
       "      <td>363</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>20130530_04_Driv_086_f</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>-15</td>\n",
       "      <td>278</td>\n",
       "      <td>183</td>\n",
       "      <td>128</td>\n",
       "      <td>141</td>\n",
       "      <td>307</td>\n",
       "      <td>218</td>\n",
       "      <td>354</td>\n",
       "      <td>210</td>\n",
       "      <td>330</td>\n",
       "      <td>247</td>\n",
       "      <td>324</td>\n",
       "      <td>273</td>\n",
       "      <td>356</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>20130530_04_Driv_087_lr</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>-30</td>\n",
       "      <td>268</td>\n",
       "      <td>186</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>296</td>\n",
       "      <td>222</td>\n",
       "      <td>344</td>\n",
       "      <td>212</td>\n",
       "      <td>319</td>\n",
       "      <td>247</td>\n",
       "      <td>316</td>\n",
       "      <td>274</td>\n",
       "      <td>347</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>20130530_04_Driv_088_lr</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>-30</td>\n",
       "      <td>264</td>\n",
       "      <td>187</td>\n",
       "      <td>127</td>\n",
       "      <td>131</td>\n",
       "      <td>287</td>\n",
       "      <td>220</td>\n",
       "      <td>334</td>\n",
       "      <td>211</td>\n",
       "      <td>304</td>\n",
       "      <td>247</td>\n",
       "      <td>305</td>\n",
       "      <td>272</td>\n",
       "      <td>337</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>20130530_04_Driv_089_f</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>-15</td>\n",
       "      <td>264</td>\n",
       "      <td>175</td>\n",
       "      <td>143</td>\n",
       "      <td>136</td>\n",
       "      <td>295</td>\n",
       "      <td>207</td>\n",
       "      <td>345</td>\n",
       "      <td>200</td>\n",
       "      <td>320</td>\n",
       "      <td>234</td>\n",
       "      <td>314</td>\n",
       "      <td>261</td>\n",
       "      <td>351</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>20130530_04_Driv_090_f</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>170</td>\n",
       "      <td>141</td>\n",
       "      <td>139</td>\n",
       "      <td>303</td>\n",
       "      <td>206</td>\n",
       "      <td>354</td>\n",
       "      <td>198</td>\n",
       "      <td>331</td>\n",
       "      <td>229</td>\n",
       "      <td>319</td>\n",
       "      <td>255</td>\n",
       "      <td>362</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fileName  subject  imgNum  label  ang   xF   yF   wF   hF  \\\n",
       "0    20130529_01_Driv_001_f         1       1      2    0  292  209  100  112   \n",
       "1    20130529_01_Driv_002_f         1       2      2    0  286  200  109  128   \n",
       "2    20130529_01_Driv_003_f         1       3      2    0  290  204  105  121   \n",
       "3    20130529_01_Driv_004_f         1       4      2    0  287  202  112  118   \n",
       "4    20130529_01_Driv_005_f         1       5      2    0  290  193  104  119   \n",
       "..                       ...      ...     ...    ...  ...  ...  ...  ...  ...   \n",
       "601  20130530_04_Driv_086_f         4      86      2  -15  278  183  128  141   \n",
       "602  20130530_04_Driv_087_lr        4      87      1  -30  268  186  128  134   \n",
       "603  20130530_04_Driv_088_lr        4      88      1  -30  264  187  127  131   \n",
       "604  20130530_04_Driv_089_f         4      89      2  -15  264  175  143  136   \n",
       "605  20130530_04_Driv_090_f         4      90      2    0  266  170  141  139   \n",
       "\n",
       "     xRE  yRE  xLE  yLE   xN   yN  xRM  yRM  xLM  yLM  \n",
       "0    323  232  367  231  353  254  332  278  361  278  \n",
       "1    324  235  366  235  353  258  333  281  361  281  \n",
       "2    325  240  367  239  351  260  334  282  362  282  \n",
       "3    325  230  369  230  353  253  335  274  362  275  \n",
       "4    325  224  366  225  353  244  333  268  363  268  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "601  307  218  354  210  330  247  324  273  356  266  \n",
       "602  296  222  344  212  319  247  316  274  347  269  \n",
       "603  287  220  334  211  304  247  305  272  337  270  \n",
       "604  295  207  345  200  320  234  314  261  351  251  \n",
       "605  303  206  354  198  331  229  319  255  362  247  \n",
       "\n",
       "[606 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label = pd.read_csv(train_directory+'/drivPoints.txt')\n",
    "df_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_augumented_images(aug_images_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
